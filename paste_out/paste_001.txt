===== BEGIN FILE =====
PATH: README.md
LINES: 259
CHUNK: 1/1
SHA256: c98645cbda516f6a178487e8e8268f8ee7ca63536a7c7e2e89021be46496b2a2
----- BEGIN CODE -----
# r\_tools

Et lettvint verktÃ¸ysett for daglig utvikling pÃ¥ Linux/Raspberry Pi. **r\_tools** samler flere smÃ¥verktÃ¸y i Ã©n konsistent CLI: sÃ¸k i kode, generer innlimingsklare Â«paste chunksÂ», list rÃ¥ GitHubâ€‘lenker og kjÃ¸r formatteringsverktÃ¸y â€“ alt konfigurerbart og kjÃ¸rbart fra hvilken som helst sti.

> Repo: `Sygaro/tools`

---

## âœ¨ HovedidÃ©

- **Ã‰n CLI (`rt`)** for alle verktÃ¸y.
- **Felles venv** og **felles config-struktur**.
- **Perâ€‘prosjekt overrides** via `.r-tools.json` i arbeidskatalogen.
- KjÃ¸r uten Ã¥ aktivere venv og uten Ã¥ cdâ€™e inn i repoet.

---

## ğŸ“¦ Innhold

- `rt search` â€“ raskt regexâ€‘sÃ¸k i prosjektfiler med farge/highlight.
- `rt paste` â€“ pakk filer i innlimingsklare tekstblokker (Â«chunksÂ») med rammeinfo.
- `rt gh-raw` â€“ list rÃ¥ GitHubâ€‘lenker for et repo/branch (ingen `jq`/`curl` nÃ¸dvendig).
- `rt format` â€“ kjÃ¸r `prettier`, `black`, `ruff` etter config.
- `rt clean` â€“ slett midlertidige/katalogâ€‘cache via trygge filtre.
- `rt list` â€“ vis effektive configâ€‘verdier og opprinnelse (hvilken fil som Â«vantÂ»).

---

## ğŸ”§ Forutsetninger

- Linux/Unix shell eller macOS.
- Python 3.10+ installert.
- (Valgfritt) VerktÃ¸y i PATH nÃ¥r brukt:
  - `npx` (for `prettier`), `black`, `ruff` dersom du bruker `rt format`.

---

## ğŸš€ Installasjon

```bash
# klon
git clone https://github.com/Sygaro/tools.git
cd tools

# gi kjÃ¸rerett pÃ¥ launcher og legg pÃ¥ PATH
chmod +x bin/rt
sudo ln -sf "$(pwd)/bin/rt" /usr/local/bin/rt

# fÃ¸rste kjÃ¸ring oppretter venv og installerer requirements automatisk
rt list
```

> **Merk:** `rt` aktiverer/bruker repoets venv automatisk. Du trenger ikke `source venv/bin/activate`.

---

## ğŸ—‚ï¸ Mappestruktur (kort)

```
tools/
â”œâ”€ bin/rt                 # launcher (aktiverer venv, starter CLI)
â”œâ”€ configs/               # globale og verktÃ¸yspesifikke JSON-konfiger
â”‚  â”œâ”€ global_config.json
â”‚  â”œâ”€ search_config.json
â”‚  â”œâ”€ paste_config.json
â”‚  â”œâ”€ gh_raw_config.json
â”‚  â””â”€ format_config.json
â”œâ”€ r_tools/               # Python-pakke (selve verktÃ¸yene)
â”‚  â”œâ”€ cli.py              # entrypoint for underkommandoer
â”‚  â”œâ”€ config.py           # lasting/merging av config + provenance
â”‚  â””â”€ tools/
â”‚     â”œâ”€ code_search.py   # rt search
â”‚     â”œâ”€ paste_chunks.py  # rt paste
â”‚     â”œâ”€ gh_raw.py        # rt gh-raw
â”‚     â”œâ”€ format_code.py   # rt format
â”‚     â””â”€ clean_temp.py    # rt clean
â””â”€ requirements.txt       # lette Python-avhengigheter
```

---

## âš™ï¸ Konfigurasjon

Konfig lastes i fÃ¸lgende prioritet (sist vinner):

1. `configs/global_config.json`
2. *Valgfritt:* verktÃ¸yspesifikk (`configs/<tool>_config.json`)
3. *Valgfritt:* prosjektâ€‘override i **arbeidskatalogen**: `./.r-tools.json`
4. *Valgfritt:* CLIâ€‘flagg

> **Viktig:** JSONâ€‘filer mÃ¥ vÃ¦re gyldig JSON â€“ **ingen kommentarer** (`//`, `/* */`)!

### Eksempel: `configs/global_config.json`

```json
{
  "project_root": ".",
  "include_extensions": [".py", ".sh", ".c", ".cpp", ".h", ".js", ".ts"],
  "exclude_dirs": ["__pycache__", "build", ".git", "node_modules", "venv"],
  "exclude_files": [],
  "case_insensitive": true,
  "paste": {
    "root": ".",
    "out_dir": "paste_out",
    "max_lines": 4000,
    "allow_binary": false,
    "include": ["**/*.py", "**/*.js", "**/*.ts", "**/*.css", "**/*.html", "**/*.json", "**/*.md", "**/*.sh"],
    "exclude": ["**/.git/**", "**/venv/**", "**/node_modules/**", "**/__pycache__/**", "**/.pytest_cache/**", "**/.mypy_cache/**", "**/.DS_Store"],
    "only_globs": [],
    "skip_globs": []
  },
  "gh_raw": { "user": "Sygaro", "repo": "countdown", "branch": "main", "path_prefix": "" },
  "format": {
    "prettier": { "enable": true, "globs": ["static/**/*.{html,css,js}"] },
    "black":    { "enable": true, "paths": ["app"] },
    "ruff":     { "enable": true, "args": ["check", "app", "--fix"] }
  },
  "clean": {
    "enable": true,
    "targets": {
      "pycache": true,
      "pytest_cache": true,
      "mypy_cache": true,
      "ruff_cache": true,
      "coverage": true,
      "build": true,
      "dist": true,
      "editor": true,
      "ds_store": true,
      "thumbs_db": true,
      "node_modules": false
    },
    "extra_globs": [],
    "skip_globs": []
  }
}
```

### Perâ€‘prosjekt override: `./.r-tools.json`

```json
{
  "project_root": ".",
  "search_terms": ["\\bclass\\b"],
  "paste": {
    "only_globs": ["app/**", "tools/**"],
    "skip_globs": ["**/dist/**", "**/*.min.js"]
  }
}
```

---

## ğŸ§° Bruk

### `rt list` â€“ vis aktiv config og opprinnelse

```bash
rt list                 # alt
rt list --tool paste    # kun pasteâ€‘delen
rt list --tool search   # kun searchâ€‘delen
```

Viser hvilke filer som ble brukt og Â«opprinnelseÂ» per nÃ¸kkel (hvem overstyrte hva).

### `rt search` â€“ regexâ€‘sÃ¸k i kode

```bash
# bruk konfigurerte sÃ¸keord
rt search

# eksplisitte regexâ€‘termer
rt search class
rt search "import\\s+os" --count
rt search --project /path/til/prosjekt --ext .py .sh --case-sensitive
```

- Filtrer pÃ¥ filendelser, ekskluder kataloger/filer via config eller CLI.
- Farge/highlight i terminal (kan skrus av med `--no-color`).

### `rt paste` â€“ generer Â«paste chunksÂ»

```bash
# list bare hvilke filer som ville blitt inkludert
rt paste --list-only

# generer filer til standard out_dir
rt paste

# overrides
rt paste --project . --out build/paste --max-lines 3000
```

- Pakker hver kildefil inn i en ramme: `BEGIN/END FILE`, `PATH`, `LINES`, `SHA256`.
- StÃ¸tter `allow_binary` (hexâ€‘dump), `only_globs` og `skip_globs` for rask filtrering.

### `rt gh-raw` â€“ list rÃ¥ GitHubâ€‘lenker

```bash
rt gh-raw
rt gh-raw --path-prefix app/routes --json
```

Returnerer `https://raw.githubusercontent.com/<user>/<repo>/<branch>/<path>` for alle filer i treet (kan filtreres med `path_prefix`).

### `rt format` â€“ kjÃ¸r formattere

```bash
rt format
rt format --dry-run
```

KjÃ¸rer `prettier` (via `npx`), `black`, `ruff` dersom de finnes i PATH og er aktivert i config.

### `rt clean` â€“ slett midlertidige filer/kataloger

```bash
# vis hva som ville blitt slettet (standard)
rt clean

# slett faktisk (krever --yes)
rt clean --yes

# begrens til gitte mÃ¥l (overstyrer config)
rt clean --what pycache ruff_cache coverage --yes

# hopp over node_modules uansett config
rt clean --skip node_modules

# tÃ¸rkekjÃ¸ring + mer pratsom
rt clean --dry-run
```

- Trygg som standard: kjÃ¸rer **dryâ€‘run** med oversikt. Du mÃ¥ eksplisitt bruke `--yes` for Ã¥ slette.
- MÃ¥l defineres i `clean.targets` i konfig (`true/false`). CLI `--what` kan snevre inn, `--skip` kan utelate.
- StÃ¸tter ekstra mÃ¸nstre i `clean.extra_globs` og unntak i `clean.skip_globs`.

---

## ğŸ§ª Tips & feilsÃ¸king

- **JSONâ€‘feil**: `rt list --tool paste` feiler ofte hvis en JSONâ€‘fil er tom/ugyldig. Valider med `jq . <fil>` (om du har `jq`).
- **PATH**: SÃ¸rg for at `/usr/local/bin/rt` peker til repoets `bin/rt`.
- **Ytelse**: bruk `only_globs`/`skip_globs` for Ã¥ redusere sÃ¸keomrÃ¥de.

---

## ğŸ›£ï¸ Veikart

- `rt paste --since <git-ref>` (kun endrede filer)
- `rt search --json` (maskinlesbar output)
- `rt gh-raw` med token fra env for hÃ¸yere rateâ€‘limit

---

## Lisens

MIT (se `LICENSE` dersom tilgjengelig).


----- END CODE -----
===== END FILE =====
===== BEGIN FILE =====
PATH: r_tools/__init__.py
LINES: 2
CHUNK: 1/1
SHA256: 0a6b11ddb78cd35267960614d82969fe0d338528e6501a43138f3c42f8524fbb
----- BEGIN CODE -----
# /home/reidar/tools/r_tools/__init__.py
__all__ = []

----- END CODE -----
===== END FILE =====
===== BEGIN FILE =====
PATH: r_tools/cli.py
LINES: 243
CHUNK: 1/1
SHA256: d6e0af50811cd9465c700884de21597e99262bc73eb34bb20429b40957e06155
----- BEGIN CODE -----
# /home/reidar/tools/r_tools/cli.py
from __future__ import annotations

import argparse
import json
import os
import subprocess
import sys
from pathlib import Path
from typing import Any, Dict, Optional

from .config import load_config, load_config_info
from .tools.code_search import run_search
from .tools.clean_temp import run_clean
from .tools.format_code import run_format
from .tools.gh_raw import run_gh_raw
from .tools.paste_chunks import run_paste

VERSION = "0.6.0"

def build_parser() -> argparse.ArgumentParser:
    p = argparse.ArgumentParser(prog="rt", description="r_tools CLI")
    p.add_argument("--version", action="store_true", help="Vis versjon og avslutt")
    sub = p.add_subparsers(dest="cmd", required=True)

    sp = sub.add_parser("search", help="SÃ¸k i prosjektfiler")
    sp.add_argument("terms", nargs="*", help="Regex-termin(e). Tom â†’ bruk config.")
    sp.add_argument("--project", type=Path)
    sp.add_argument("--ext", nargs="*")
    sp.add_argument("--include-dir", nargs="*", default=[])
    sp.add_argument("--exclude-dir", nargs="*", default=[])
    sp.add_argument("--exclude-file", nargs="*", default=[])
    sp.add_argument("--case-sensitive", action="store_true")
    sp.add_argument("--no-color", action="store_true")
    sp.add_argument("--count", action="store_true")
    sp.add_argument("--max-size", type=int, default=2_000_000)
    sp.add_argument("--all", action="store_true", help="Krev at alle termer matcher samme linje")

    pp = sub.add_parser("paste", help="Lag innlimingsklare filer (chunks)")
    pp.add_argument("--project", type=Path, help="Overstyr paste.root")
    pp.add_argument("--out", type=Path, help="Overstyr paste.out_dir")
    pp.add_argument("--max-lines", type=int, help="Overstyr paste.max_lines")
    pp.add_argument("--allow-binary", action="store_true")
    pp.add_argument("--include", action="append", default=None)
    pp.add_argument("--exclude", action="append", default=None)
    pp.add_argument("--list-only", action="store_true")

    gp = sub.add_parser("gh-raw", help="List raw GitHub-URLer for repo tree")
    gp.add_argument("--user")
    gp.add_argument("--repo")
    gp.add_argument("--branch")
    gp.add_argument("--path-prefix", default="")
    gp.add_argument("--json", action="store_true")

    fp = sub.add_parser("format", help="KjÃ¸r prettier/black/ruff ihht config")
    fp.add_argument("--dry-run", action="store_true")

    cp = sub.add_parser("clean", help="Slett midlertidige filer/kataloger")
    cp.add_argument("--project", type=Path, help="Overstyr project_root")
    cp.add_argument("--what", nargs="*", choices=[
        "pycache","pytest_cache","mypy_cache","ruff_cache","coverage","build","dist",
        "editor","ds_store","thumbs_db","node_modules"
    ], help="Begrens til disse mÃ¥lene")
    cp.add_argument("--skip", nargs="*", default=[], help="Hopp over disse mÃ¥lene")
    cp.add_argument("--dry-run", action="store_true", help="Vis hva som slettes uten Ã¥ slette")
    cp.add_argument("--yes", action="store_true", help="UtfÃ¸r faktisk sletting")
    cp.add_argument("--extra", nargs="*", default=None, help="Tilleggs-globs Ã¥ slette")

    sv = sub.add_parser("serve", help="Start web-UI server")
    sv.add_argument("--host", default="0.0.0.0")
    sv.add_argument("--port", type=int, default=8765)

    lp = sub.add_parser("list", help="Vis config-kilder/verdier og opprinnelse (diff)")
    lp.add_argument("--tool", choices=["search", "paste", "gh_raw", "format", "clean"], help="Begrens til et verktÃ¸y")
    lp.add_argument("--project", type=Path)

    return p

def _print_debug_header():
    if os.environ.get("RT_DEBUG") == "1":
        try:
            import r_tools, inspect
            print(f"[rt] python: {sys.executable}")
            print(f"[rt] r_tools: {inspect.getsourcefile(r_tools) or r_tools.__file__}")
        except Exception as e:
            print(f"[rt] debug error: {e}")

def main() -> None:
    parser = build_parser()
    args = parser.parse_args()

    if args.version:
        print(f"r_tools {VERSION}")
        return

    _print_debug_header()

    if args.cmd == "search":
        cli_overrides: Dict[str, Any] = {}
        if args.ext:
            cli_overrides["include_extensions"] = args.ext
        if args.exclude_dir or args.include_dir or args.exclude_file:
            cli_overrides.setdefault("exclude_dirs", [])
            cli_overrides.setdefault("exclude_files", [])
            cli_overrides["exclude_dirs"] += args.exclude_dir
            cli_overrides["exclude_files"] += args.exclude_file
        if args.case_sensitive:
            cli_overrides["case_insensitive"] = False

        cfg = load_config("search_config.json", args.project, cli_overrides or None)
        run_search(
            cfg=cfg,
            terms=args.terms or None,
            use_color=not args.no_color,
            show_count=args.count,
            max_size=args.max_size,
            require_all=args.all,
        )
        return

    if args.cmd == "paste":
        ov: Dict[str, Any] = {"paste": {}}
        if args.out:        ov["paste"]["out_dir"] = str(args.out)
        if args.project:    ov["paste"]["root"] = str(args.project)
        if args.max_lines:  ov["paste"]["max_lines"] = args.max_lines
        if args.allow_binary: ov["paste"]["allow_binary"] = True
        if args.include:    ov["paste"]["include"] = args.include
        if args.exclude:    ov["paste"]["exclude"] = args.exclude
        cfg = load_config("paste_config.json", None, ov)
        run_paste(cfg, list_only=args.list_only)
        return

    if args.cmd == "gh-raw":
        ov = {"gh_raw": {}}
        if args.user:       ov["gh_raw"]["user"] = args.user
        if args.repo:       ov["gh_raw"]["repo"] = args.repo
        if args.branch:     ov["gh_raw"]["branch"] = args.branch
        if args.path_prefix is not None: ov["gh_raw"]["path_prefix"] = args.path_prefix
        cfg = load_config("gh_raw_config.json", None, ov)
        run_gh_raw(cfg, as_json=args.json)
        return

    if args.cmd == "format":
        cfg = load_config("format_config.json")
        run_format(cfg, dry_run=args.dry_run)
        return

    if args.cmd == "clean":
        ov: Dict[str, Any] = {}
        if args.project: ov["project_root"] = str(args.project)
        if args.extra is not None:
            ov.setdefault("clean", {}); ov["clean"]["extra_globs"] = args.extra
        cfg = load_config("clean_config.json", None, ov)
        run_clean(cfg, only=args.what, skip=args.skip, dry_run=(not args.yes) or args.dry_run)
        return

    if args.cmd == "serve":
        import signal, time
        host = getattr(args, "host", "0.0.0.0")
        port = str(getattr(args, "port", 8765))

        try:
            import uvicorn  # noqa: F401
        except Exception as e:
            print(f"[serve] uvicorn mangler i venv: {e}")
            print("Tips: /home/reidar/tools/venv/bin/pip install uvicorn fastapi pydantic")
            sys.exit(1)

        cmd = [
            sys.executable, "-m", "uvicorn", "r_tools.tools.webui:app",
            "--host", host, "--port", port, "--log-level", "info"
        ]
        print("[serve] Kommando:", " ".join(cmd))
        print(f"[serve] Starter r_tools UI pÃ¥ http://{host}:{port} (Ctrl+C for Ã¥ stoppe)")

        # Start barneprosess, og hÃ¥ndter Ctrl+C selv for pen shutdown
        proc = subprocess.Popen(cmd)
        try:
            rc = proc.wait()
            print(f"[serve] uvicorn avsluttet med kode {rc}")
            sys.exit(rc)
        except KeyboardInterrupt:
            print("\n[serve] Avslutter â€¦ (Ctrl+C)")
            try:
                proc.send_signal(signal.SIGINT)  # be uvicorn stoppe pent
                rc = proc.wait(timeout=8)
            except subprocess.TimeoutExpired:
                proc.terminate()
                try:
                    rc = proc.wait(timeout=3)
                except subprocess.TimeoutExpired:
                    proc.kill()
                    rc = proc.wait()
            print(f"[serve] Stoppet (exit {rc})")
            sys.exit(0)


    if args.cmd == "list":
        tool_to_cfg = {
            None: None,
            "search": "search_config.json",
            "paste": "paste_config.json",
            "gh_raw": "gh_raw_config.json",
            "format": "format_config.json",
            "clean": "clean_config.json",
        }
        cfg, info = load_config_info(tool_to_cfg[args.tool] if args.tool else None,
                                     project_override=args.project)
        print("== Kilder ==")
        for k in ["tools_root", "global_config", "tool_config", "project_file", "project_override"]:
            print(f"{k:18}: {info.get(k)}")

        if args.tool == "search":
            eff = {k: cfg.get(k) for k in ["project_root", "include_extensions", "exclude_dirs", "exclude_files", "case_insensitive", "search_terms"]}
            base = "search"
        elif args.tool == "paste":
            eff = cfg.get("paste", {}); base = "paste"
        elif args.tool == "gh_raw":
            eff = cfg.get("gh_raw", {}); base = "gh_raw"
        elif args.tool == "format":
            eff = cfg.get("format", {}); base = "format"
        elif args.tool == "clean":
            eff = cfg.get("clean", {}); base = "clean"
        else:
            eff = cfg; base = ""

        print("\n== Effektiv config ==")
        print(json.dumps(eff, indent=2, ensure_ascii=False))

        print("\n== Opprinnelse (siste skriver vinner) ==")
        prov = info.get("provenance", {})
        for k in sorted(prov):
            if base and not k.startswith(base + "."):
                continue
            print(f"{k:40} â† {prov[k]}")
        return

    # Fallback: skulle aldri treffes
    print(f"Ukjent kommando: {args.cmd!r}")
    sys.exit(2)

if __name__ == "__main__":
    main()

----- END CODE -----
===== END FILE =====
===== BEGIN FILE =====
PATH: r_tools/config.py
LINES: 103
CHUNK: 1/1
SHA256: 6493aee9dc4329962031026698da2b0ca23dbf3829329d06256913f9a70b4700
----- BEGIN CODE -----
# /home/reidar/tools/r_tools/config.py
from __future__ import annotations
import json
from pathlib import Path
from typing import Any, Dict, Tuple, Optional

TOOLS_ROOT = Path(__file__).resolve().parents[1]
GLOBAL_CONFIG = TOOLS_ROOT / "configs" / "global_config.json"

def _load_json(path: Path) -> Dict[str, Any]:
    if not path.is_file():
        return {}
    try:
        text = path.read_text(encoding="utf-8")
        if not text.strip():
            print(f"[advarsel] Tom JSON-fil ignorert: {path}")
            return {}
        return json.loads(text)
    except json.JSONDecodeError as e:
        print(f"[advarsel] Ugyldig JSON i {path}: {e}")
        return {}
    except Exception as e:
        print(f"[advarsel] Kunne ikke lese {path}: {e}")
        return {}

def deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
    out = dict(base)
    for k, v in override.items():
        if isinstance(v, dict) and isinstance(out.get(k), dict):
            out[k] = deep_merge(out[k], v)
        else:
            out[k] = v
    return out

def _flatten(d: Dict[str, Any], prefix: str = "") -> Dict[str, Any]:
    flat: Dict[str, Any] = {}
    for k, v in d.items():
        key = f"{prefix}.{k}" if prefix else k
        if isinstance(v, dict):
            flat.update(_flatten(v, key))
        else:
            flat[key] = v
    return flat

def _merge_with_provenance(layers: list[tuple[str, Dict[str, Any]]]) -> tuple[Dict[str, Any], Dict[str, str]]:
    merged: Dict[str, Any] = {}
    prov: Dict[str, str] = {}
    for name, cfg in layers:
        merged = deep_merge(merged, cfg)
        flat = _flatten(cfg)
        for k in flat.keys():
            prov[k] = name  # siste lag vinner
    return merged, prov

def load_config_info(tool_config_name: Optional[str] = None,
                     project_override: Optional[Path] = None,
                     cli_overrides: Optional[Dict[str, Any]] = None
                     ) -> Tuple[Dict[str, Any], Dict[str, Any]]:
    info: Dict[str, Any] = {
        "tools_root": str(TOOLS_ROOT),
        "global_config": str(GLOBAL_CONFIG),
        "tool_config": None,
        "project_file": None,
        "project_override": str(project_override) if project_override else None,
        "cli_overrides": cli_overrides or {}
    }

    layers: list[tuple[str, Dict[str, Any]]] = []
    g = _load_json(GLOBAL_CONFIG)
    layers.append(("global_config", g))

    tool_cfg_path = None
    if tool_config_name:
        tool_cfg_path = TOOLS_ROOT / "configs" / tool_config_name
        info["tool_config"] = str(tool_cfg_path)
        layers.append((tool_config_name, _load_json(tool_cfg_path)))

    project_file = Path.cwd() / ".r-tools.json"
    if project_file.is_file():
        info["project_file"] = str(project_file)
        layers.append((".r-tools.json", _load_json(project_file)))

    if project_override:
        layers.append(("project_override", {"project_root": str(project_override)}))

    if cli_overrides:
        layers.append(("cli_overrides", cli_overrides))

    cfg, prov = _merge_with_provenance(layers)

    cfg.setdefault("include_extensions", [])
    cfg.setdefault("exclude_dirs", [])
    cfg.setdefault("exclude_files", [])
    cfg.setdefault("case_insensitive", True)

    info["provenance"] = prov
    return cfg, info

def load_config(tool_config_name: Optional[str] = None,
                project_override: Optional[Path] = None,
                cli_overrides: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    cfg, _ = load_config_info(tool_config_name, project_override, cli_overrides)
    return cfg

----- END CODE -----
===== END FILE =====
===== BEGIN FILE =====
PATH: r_tools/tools/__init__.py
LINES: 2
CHUNK: 1/1
SHA256: d5fd29d4409ddd059ecbcae1bb2aca3877c9dbdcb1cf50f6b320c8f9d35c57f6
----- BEGIN CODE -----
# /home/reidar/tools/reidar_tools/tools/__init__.py
__all__ = []

----- END CODE -----
===== END FILE =====
===== BEGIN FILE =====
PATH: r_tools/tools/clean_temp.py
LINES: 164
CHUNK: 1/1
SHA256: 9d4f0b26b3dcc6bd27d0090eae2d1929f45d6a36b828f71729e014f3686d3c96
----- BEGIN CODE -----
# /home/reidar/tools/r_tools/tools/clean_temp.py
from __future__ import annotations
import os
from pathlib import Path
from typing import Dict, Iterable, List, Tuple

# Katalognavn vi gjenkjenner direkte (rask sjekk pÃ¥ path.parts)
_DIR_TARGETS = {
    "pycache": {"__pycache__"},
    "pytest_cache": {".pytest_cache"},
    "mypy_cache": {".mypy_cache"},
    "ruff_cache": {".ruff_cache"},
    "coverage": {"htmlcov"},
    "build": {"build"},
    "dist": {"dist"},
    "node_modules": {"node_modules"},
}

# Filnavn/globs per mÃ¥l
_FILE_PATTERNS = {
    "coverage": [".coverage", ".coverage.*"],
    "editor": ["*~", ".*.swp", ".*.swo", "*.tmp", "*.bak"],
    "ds_store": [".DS_Store"],
    "thumbs_db": ["Thumbs.db", "ehthumbs.db"],
}

def _match_any_name(path: Path, names: Iterable[str]) -> bool:
    s = set(path.parts)
    return any(n in s for n in names)

def _gather_targets(root: Path, enabled: Dict[str, bool],
                    extra_globs: List[str], skip_globs: List[str],
                    only: List[str] | None, skip: List[str] | None) -> Tuple[List[Path], List[Path]]:
    """
    Returner (dirs, files) for sletting.
    - only: begrens til disse target-keyene
    - skip: hopp over disse target-keyene
    """
    only_set = set(only or [])
    skip_set = set(skip or [])

    def is_on(key: str) -> bool:
        if key in skip_set:
            return False
        if only_set and key not in only_set:
            return False
        return bool(enabled.get(key, False))

    del_dirs: List[Path] = []
    del_files: List[Path] = []

    # 1) katalogmÃ¥l (rask navne-match)
    for dirpath, dirnames, filenames in os.walk(root, topdown=True, followlinks=False):
        pdir = Path(dirpath)

        # bygg liste over direr som skal slettes i denne mappen
        to_remove_names: List[str] = []
        for key, names in _DIR_TARGETS.items():
            if not is_on(key):
                continue
            for d in list(dirnames):
                if d in names:
                    to_remove_names.append(d)

        # legg til i del_dirs og fjern fra traversal (unngÃ¥ rglob inni)
        for name in to_remove_names:
            target = (pdir / name).resolve()
            if target.is_dir():
                del_dirs.append(target)
                # fjern fra videre os.walk
                if name in dirnames:
                    dirnames.remove(name)

        # 2) file-patterns per mÃ¥l
        for key, patterns in _FILE_PATTERNS.items():
            if not is_on(key):
                continue
            for pat in patterns:
                for f in pdir.glob(pat):
                    if f.is_file():
                        del_files.append(f.resolve())

    # 3) ekstra globs
    for pat in extra_globs or []:
        for p in root.glob(pat):
            if p.is_file():
                del_files.append(p.resolve())
            elif p.is_dir():
                del_dirs.append(p.resolve())

    # 4) skip_globs (filter bort)
    def should_skip(path: Path) -> bool:
        for pat in skip_globs or []:
            # tolkes relativt til root
            for m in (root.glob(pat) if any(ch in pat for ch in "*?[]") else [root / pat]):
                try:
                    if m.resolve() == path:
                        return True
                except Exception:
                    pass
        return False

    del_dirs = [d for d in sorted(set(del_dirs)) if not should_skip(d)]
    del_files = [f for f in sorted(set(del_files)) if not should_skip(f)]
    return del_dirs, del_files

def _rm_dir(p: Path) -> bool:
    try:
        # rask og trygg: fjern tre rekursivt
        for sub in p.rglob("*"):
            try:
                if sub.is_file() or sub.is_symlink():
                    sub.unlink(missing_ok=True)
            except Exception:
                pass
        for sub in sorted([q for q in p.rglob("*") if q.is_dir()], reverse=True):
            try:
                sub.rmdir()
            except Exception:
                pass
        p.rmdir()
        return True
    except Exception:
        return False

def _rm_file(p: Path) -> bool:
    try:
        p.unlink(missing_ok=True)
        return True
    except Exception:
        return False

def run_clean(cfg: Dict, only: List[str] | None, skip: List[str],
              dry_run: bool = True) -> None:
    root = Path(cfg.get("project_root", ".")).resolve()
    c = cfg.get("clean", {})
    if not c or not c.get("enable", True):
        print("Clean er slÃ¥tt av i config (â€˜clean.enable=falseâ€™).")
        return

    enabled = dict(c.get("targets", {}))
    extra_globs = list(c.get("extra_globs", []))
    skip_globs = list(c.get("skip_globs", []))

    dirs, files = _gather_targets(root, enabled, extra_globs, skip_globs, only, skip)

    print(f"Prosjekt: {root}")
    print(f"Fjernes (kataloger): {len(dirs)}")
    for d in dirs:
        print("  DIR ", d.relative_to(root))
    print(f"Fjernes (filer): {len(files)}")
    for f in files:
        print("  FILE", f.relative_to(root))

    if dry_run:
        print("Dry-run: ingen filer/kataloger ble slettet. Bruk --yes for Ã¥ utfÃ¸re.")
        return

    ok = 0; fail = 0
    for d in dirs:
        (_rm_dir(d) and (ok:=ok+1)) or (fail:=fail+1)
    for f in files:
        (_rm_file(f) and (ok:=ok+1)) or (fail:=fail+1)
    print(f"Slettet: {ok} â€¢ Feilet: {fail}")

----- END CODE -----
===== END FILE =====
===== BEGIN FILE =====
PATH: r_tools/tools/code_search.py
LINES: 92
CHUNK: 1/1
SHA256: aa012fb94712216cde4d4e6b4807510e898eb26086ae596656ebd73224f31ac7
----- BEGIN CODE -----
from __future__ import annotations
import os, re
from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, List, Dict, Tuple
from colorama import Fore, Style, init as colorama_init

colorama_init(autoreset=True)

@dataclass
class SearchConfig:
    project_root: Path
    include_extensions: List[str]
    exclude_dirs: List[str]
    exclude_files: List[str]
    case_insensitive: bool

def _compile_patterns(terms: Iterable[str], flags: int) -> List[re.Pattern]:
    return [re.compile(t, flags=flags) for t in terms]

def _should_include(path: Path, cfg: SearchConfig) -> bool:
    if not any(str(path).endswith(ext) for ext in cfg.include_extensions):
        return False
    if path.name in set(cfg.exclude_files):
        return False
    parts = set(path.parts)
    if any(ex in parts for ex in cfg.exclude_dirs):
        return False
    return True

def _highlight(line: str, patterns: List[re.Pattern], use_color: bool) -> str:
    if not use_color:
        return line.rstrip("\n")
    out = line.rstrip("\n")
    for pat in patterns:
        out = pat.sub(lambda m: f"{Fore.YELLOW}{m.group(0)}{Style.RESET_ALL}", out)
    return out

def _iter_files(root: Path) -> Iterable[Path]:
    for dirpath, _, filenames in os.walk(root):
        for f in filenames:
            yield Path(dirpath) / f

def run_search(
    cfg: Dict,
    terms: List[str] | None,
    use_color: bool,
    show_count: bool,
    max_size: int,
    require_all: bool = False,  # â† NYTT
) -> None:
    sc = SearchConfig(
        project_root=Path(cfg["project_root"]),
        include_extensions=list(cfg["include_extensions"]),
        exclude_dirs=list(cfg["exclude_dirs"]),
        exclude_files=list(cfg["exclude_files"]),
        case_insensitive=bool(cfg.get("case_insensitive", True)),
    )

    search_terms = terms if terms else list(cfg.get("search_terms", []))
    if not search_terms:
        print("Ingen sÃ¸ketermer. Angi termer eller legg til i config.")
        return

    flags = re.IGNORECASE if sc.case_insensitive else 0
    patterns = _compile_patterns(search_terms, flags)

    total_hits = 0
    for file_path in _iter_files(sc.project_root):
        try:
            if not _should_include(file_path, sc):
                continue
            if file_path.stat().st_size > max_size:
                continue

            matches: List[Tuple[int, str]] = []
            with file_path.open("r", encoding="utf-8", errors="ignore") as f:
                for idx, line in enumerate(f, 1):
                    has_match = all(p.search(line) for p in patterns) if require_all else any(p.search(line) for p in patterns)
                    if has_match:
                        matches.append((idx, _highlight(line, patterns, use_color)))

            if matches:
                if show_count:
                    print(f"{Fore.CYAN}{file_path}{Style.RESET_ALL}  (+{len(matches)} treff)")
                for ln, content in matches:
                    print(f"{Fore.CYAN}{file_path}:{ln}:{Style.RESET_ALL} {content}")
                total_hits += len(matches)
        except Exception as e:
            print(f"{Fore.RED}Feil pÃ¥ {file_path}: {e}{Style.RESET_ALL}")

    print(f"{Fore.GREEN}Totalt treff: {total_hits}{Style.RESET_ALL}")

----- END CODE -----
===== END FILE =====
===== BEGIN FILE =====
PATH: r_tools/tools/format_code.py
LINES: 285
CHUNK: 1/1
SHA256: ef49b6dd00fe74989742e4574760c17c1ee62d654b0875b88e586fc4ca4c7b2a
----- BEGIN CODE -----
# /home/reidar/tools/r_tools/tools/format_code.py
"""
Formatterings-pipeline:
- prettier (via npx), black, ruff
- Whitespace-cleanup (styrt via config):
  * Alltid: fjern trailing spaces, normaliser LF + eksakt 1 sluttlinje
  * Alltid: trim tomlinjer i start/slutt av fil
  * Alltid: kollaps serier av tomlinjer til maks N (N = cleanup.max_consecutive_blanks, default 1)
  * Hvis cleanup.compact_blocks=true:
      - Python: fjern tom linje etter blokksstart (linjer som ender med ':'),
        unntatt hvis neste ikke-tomme er docstring; fjern tom linje fÃ¸r
        else/elif/except/finally.
      - {}-sprÃ¥k: fjern tom linje etter '{' og fÃ¸r '}'/'};'
  * Hopper over filendelser definert i cleanup.exclude_exts
Hvorfor: gi kontroll pÃ¥ hvor aggressiv innstramming skal vÃ¦re og hvilke filer som ryddes.
"""
from __future__ import annotations
import subprocess
import shutil
import sys
from pathlib import Path
from typing import Dict, List, Optional, Iterable

# ---------- Runner utils ----------

def _which_tool(name: str) -> Optional[str]:
    """Finn binÃ¦r i samme venv som sys.executable, ellers i PATH."""
    exe = Path(sys.executable)
    candidate = exe.with_name(name)
    if candidate.exists() and candidate.is_file():
        return str(candidate)
    found = shutil.which(name)
    if found:
        return found
    return None

def _run(cmd: List[str], dry: bool) -> int:
    print("â–¶", " ".join(cmd))
    if dry:
        return 0
    try:
        # Viktig: stderrâ†’stdout, sÃ¥ web-UI fanger alt
        proc = subprocess.run(cmd, check=False, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
        if proc.stdout:
            # videreskriv til vÃ¥r stdout (fanges av webui._capture)
            print(proc.stdout, end="")
        return proc.returncode
    except FileNotFoundError:
        print(f"VerktÃ¸y ikke funnet: {cmd[0]}")
        return 127

# ---------- Cleanup: helpers ----------

_TEXT_EXTS_DEFAULT = [".py", ".js", ".ts", ".tsx", ".css", ".scss", ".html", ".json", ".sh", ".c", ".h", ".cpp"]

def _read_text(path: Path) -> str:
    return path.read_text(encoding="utf-8", errors="replace")

def _write_if_changed(path: Path, new_text: str) -> bool:
    old = _read_text(path)
    if old != new_text:
        path.write_text(new_text, encoding="utf-8")
        return True
    return False

def _normalize_newlines(text: str) -> str:
    t = text.replace("\r\n", "\n").replace("\r", "\n")
    if not t.endswith("\n"):
        t += "\n"
    return t

def _strip_trailing_spaces(lines: List[str]) -> List[str]:
    return [ln.rstrip() for ln in lines]

def _trim_file_blank_edges(lines: List[str]) -> List[str]:
    while lines and lines[0].strip() == "":
        lines.pop(0)
    while lines and lines[-1].strip() == "":
        lines.pop()
    return lines

def _collapse_blank_runs(lines: List[str], keep: int = 1) -> List[str]:
    out: List[str] = []
    streak = 0
    for ln in lines:
        if ln.strip() == "":
            streak += 1
            if streak <= keep:
                out.append("")
        else:
            streak = 0
            out.append(ln)
    return out

# ---------- Python-specific (kompakte blokker) ----------

def _is_docstring_start(line: str) -> bool:
    s = line.lstrip()
    return s.startswith('"""') or s.startswith("'''")

def _py_remove_blank_after_any_block(lines: List[str]) -> List[str]:
    """Fjern tomlinje etter ALLE blokkslinjer (slutter med ':'), unntak for docstring."""
    out: List[str] = []
    i = 0
    n = len(lines)
    while i < n:
        out.append(lines[i])
        cur = lines[i].rstrip()
        if cur.endswith(":"):
            # dropp Ã©n tomlinje hvis neste ikke-tomme ikke er docstring
            if i + 1 < n and lines[i + 1].strip() == "":
                j = i + 2
                while j < n and lines[j].strip() == "":
                    j += 1
                if j < n and not _is_docstring_start(lines[j]):
                    i += 1
        i += 1
    return out

def _py_remove_blank_before_block_followups(lines: List[str]) -> List[str]:
    """Fjern tomlinje fÃ¸r else/elif/except/finally."""
    followups = ("else:", "elif ", "except", "finally:")
    out: List[str] = []
    i = 0
    n = len(lines)
    while i < n:
        if i + 1 < n and lines[i].strip() == "" and any(lines[i + 1].lstrip().startswith(t) for t in followups):
            i += 1
            continue
        out.append(lines[i])
        i += 1
    return out

# ---------- {}-languages (kompakte blokker) ----------

def _brace_lang_remove_unneeded_blanks(lines: List[str]) -> List[str]:
    """Fjern tom linje etter '{' og fÃ¸r '}'/'};'."""
    out: List[str] = []
    n = len(lines)
    for idx, ln in enumerate(lines):
        stripped = ln.strip()
        if stripped == "":
            prev = lines[idx - 1].strip() if idx > 0 else ""
            nxt = lines[idx + 1].strip() if idx + 1 < n else ""
            if prev.endswith("{"):
                continue
            if nxt.startswith("}") or nxt.startswith("};"):
                continue
        out.append(ln)
    return out

# ---------- Cleanup orchestrator ----------

def _cleanup_text(text: str, ext: str, compact_blocks: bool, max_consecutive_blanks: int) -> str:
    """Konservativ fÃ¸rst; stram opp blokker hvis compact_blocks=True; kollaps tomlinjer til maks N."""
    t = _normalize_newlines(text)
    lines = t.split("\n")

    lines = _strip_trailing_spaces(lines)
    lines = _trim_file_blank_edges(lines)

    low = ext.lower()
    if compact_blocks:
        if low == ".py":
            lines = _py_remove_blank_after_any_block(lines)
            lines = _py_remove_blank_before_block_followups(lines)
        elif low in {".js", ".ts", ".tsx", ".css", ".scss", ".json", ".c", ".h", ".cpp"}:
            lines = _brace_lang_remove_unneeded_blanks(lines)

    # Kollaps serier av tomlinjer til maks N
    keep_n = max(0, int(max_consecutive_blanks))
    lines = _collapse_blank_runs(lines, keep=keep_n)
    lines = _trim_file_blank_edges(lines)

    return "\n".join(lines) + "\n"

def _iter_cleanup_targets(project_root: Path, paths: List[str], exts: List[str], exclude_exts: List[str]) -> Iterable[Path]:
    """Finn filer Ã¥ rydde: rekursivt under oppgitte paths (eller root)."""
    roots: List[Path] = []
    if paths:
        for p in paths:
            pp = (project_root / p) if not Path(p).is_absolute() else Path(p)
            if pp.exists():
                roots.append(pp)
    else:
        roots.append(project_root)

    seen: set[Path] = set()
    excl = {e.lower() for e in exclude_exts}
    inc = {e.lower() for e in exts}

    def _want(p: Path) -> bool:
        sfx = p.suffix.lower()
        if sfx in excl:
            return False  # hvorfor: eksplisitt unntak
        return sfx in inc

    for base in roots:
        if base.is_file():
            if _want(base):
                yield base.resolve()
            continue
        for p in base.rglob("*"):
            if p.is_file() and _want(p):
                rp = p.resolve()
                if rp not in seen:
                    seen.add(rp)
                    yield rp

def _run_cleanup(cfg: Dict, dry_run: bool) -> None:
    fmt = cfg.get("format", {})
    cln = fmt.get("cleanup", {})
    if not cln or not cln.get("enable", False):
        return

    project_root = Path(cfg.get("project_root", ".")).resolve()
    paths = list(cln.get("paths", []))
    exts = [e.lower() for e in (cln.get("exts") or _TEXT_EXTS_DEFAULT)]
    exclude_exts = [e.lower() for e in (cln.get("exclude_exts") or [])]
    compact_blocks = bool(cln.get("compact_blocks", True))
    max_consecutive_blanks = int(cln.get("max_consecutive_blanks", 1))

    changed = 0
    total = 0
    for file_path in _iter_cleanup_targets(project_root, paths, exts, exclude_exts):
        total += 1
        try:
            original = _read_text(file_path)
            new_text = _cleanup_text(
                original,
                file_path.suffix,
                compact_blocks=compact_blocks,
                max_consecutive_blanks=max_consecutive_blanks,
            )
            if original != new_text:
                print(f"âŸ³ cleanup {file_path}")
                if not dry_run:
                    _write_if_changed(file_path, new_text)
                changed += 1
        except Exception as e:
            print(f"Feil under cleanup {file_path}: {e}")

    print(f"Cleanup: {changed}/{total} filer endret")

# ---------- Public API ----------

def run_format(cfg: Dict, dry_run: bool = False) -> None:
    fmt = cfg.get("format", {})
    rc = 0

    # prettier
    pr = fmt.get("prettier", {})
    if pr.get("enable", False):
        npx = _which_tool("npx") or "npx"
        if shutil.which(npx) or npx != "npx":
            for g in pr.get("globs", []):
                rc |= _run([npx, "prettier", "--write", g], dry_run)
        else:
            print("npx ikke funnet â€“ hopper over prettier.")

    # black
    bl = fmt.get("black", {})
    if bl.get("enable", False):
        black_bin = _which_tool("black")
        if black_bin:
            rc |= _run([black_bin] + bl.get("paths", []), dry_run)
        else:
            print("black ikke funnet i PATH â€“ prÃ¸ver fallback via python -m black â€¦")
            rc |= _run([sys.executable, "-m", "black"] + bl.get("paths", []), dry_run)

    # ruff
    rf = fmt.get("ruff", {})
    if rf.get("enable", False):
        ruff_bin = _which_tool("ruff")
        if ruff_bin:
            rc |= _run([ruff_bin] + rf.get("args", []), dry_run)
        else:
            print("ruff ikke funnet i PATH â€“ prÃ¸ver fallback via python -m ruff â€¦")
            rc |= _run([sys.executable, "-m", "ruff"] + rf.get("args", []), dry_run)

    # Whitespace-cleanup til slutt
    _run_cleanup(cfg, dry_run)

    if rc != 0:
        print(f"Noen formattere returnerte kode {rc}")

----- END CODE -----
===== END FILE =====
===== BEGIN FILE =====
PATH: r_tools/tools/gh_raw.py
LINES: 75
CHUNK: 1/1
SHA256: 6ff05a52d5f6890c5c3b92e7444c9cad7a18da4bc262a6b2af921dc0fea06ea1
----- BEGIN CODE -----
# /home/reidar/tools/r_tools/tools/gh_raw.py
from __future__ import annotations

import json
import os
from typing import Any, Dict, List
from urllib.error import HTTPError, URLError
from urllib.request import Request, urlopen


def _fetch_tree(user: str, repo: str, branch: str, token: str | None) -> Dict[str, Any]:
    """
    Hent Git tree for gitt branch. Bruker GitHub API v3.
    - token (valgfri): bruk GITHUB_TOKEN for private repo/hÃ¸yere rate-limit.
    """
    url = f"https://api.github.com/repos/{user}/{repo}/git/trees/{branch}?recursive=1"
    headers = {"User-Agent": "r_tools/gh_raw"}
    if token:
        headers["Authorization"] = f"Bearer {token}"

    req = Request(url, headers=headers)
    try:
        with urlopen(req, timeout=30) as resp:
            return json.loads(resp.read().decode("utf-8"))
    except HTTPError as e:
        msg = f"HTTP {e.code} for {url}. "
        if e.code == 404:
            msg += (
                "Sjekk at user/repo/branch stemmer, og at branchen eksisterer. "
                "Er repo privat? Sett GITHUB_TOKEN i miljÃ¸et."
            )
        raise RuntimeError(msg) from e
    except URLError as e:
        raise RuntimeError(f"Nettverksfeil mot {url}: {e.reason}") from e


def run_gh_raw(cfg: Dict, as_json: bool = False) -> None:
    """
    Les 'gh_raw' fra cfg og skriv raw.githubusercontent-URLer for alle blobs i treet.
    Respekterer evt. path_prefix for Ã¥ begrense output.
    """
    gh = cfg.get("gh_raw", {})
    user = gh.get("user")
    repo = gh.get("repo")
    branch = gh.get("branch", "main")
    path_prefix = (gh.get("path_prefix") or "").rstrip("/")
    token = os.environ.get("GITHUB_TOKEN")

    if not user or not repo:
        print("gh_raw: mangler 'user' eller 'repo' i config.")
        return

    tree = _fetch_tree(user, repo, branch, token)
    nodes: List[Dict[str, Any]] = list(tree.get("tree", []))
    if not nodes:
        print("gh_raw: tomt tre eller mangler 'tree' i responsen.")
        return

    base = f"https://raw.githubusercontent.com/{user}/{repo}/{branch}/"
    out: List[str] = []
    for node in nodes:
        if node.get("type") != "blob":
            continue
        p = node.get("path", "")
        if path_prefix:
            if p == path_prefix or p.startswith(path_prefix + "/"):
                out.append(base + p)
        else:
            out.append(base + p)

    if as_json:
        print(json.dumps(out, indent=2))
    else:
        for u in out:
            print(u)

----- END CODE -----
===== END FILE =====
===== BEGIN FILE =====
PATH: r_tools/tools/paste_chunks.py
LINES: 315
CHUNK: 1/1
SHA256: cd405c6db05357c4c776313c6fc7daa563ca3591fce67331f01c19e33f4f7182
----- BEGIN CODE -----
# /home/reidar/tools/r_tools/tools/paste_chunks.py
"""
Integrasjon av make_paste_chunks.py:
- Leser config: cfg['paste'] {root,out_dir,max_lines,allow_binary,include,exclude,only_globs,skip_globs,filename_search}
- --list-only stÃ¸ttes
- Etter kjÃ¸ring: skriver liste over inkluderte filer til stdout + out_dir/FILES.txt
- filename_search: mÃ¸nstre uten '/' tolkes som globale ('**/<mÃ¸nster>') for bÃ¥de include og exclude
"""
from __future__ import annotations
from pathlib import Path
from typing import List, Tuple, Dict
import hashlib, os

FRAME_TOP = "===== BEGIN FILE ====="
FRAME_END = "===== END FILE ====="
CODE_BEGIN = "----- BEGIN CODE -----"
CODE_END = "----- END CODE -----"

def _sha256_file(path: Path) -> str:
    h = hashlib.sha256()
    with path.open("rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            h.update(chunk)
    return h.hexdigest()

def _is_text_utf8(path: Path) -> bool:
    try:
        with path.open("rb") as f:
            data = f.read()
        data.decode("utf-8")
        return True
    except Exception:
        return False

def _read_text_utf8(path: Path) -> str:
    with path.open("rb") as f:
        data = f.read()
    return data.decode("utf-8", errors="replace")

def _normalize_newlines(s: str) -> str:
    return s.replace("\r\n", "\n").replace("\r", "\n")

def _brace_expand_one(pattern: str) -> List[str]:
    start = pattern.find("{")
    if start == -1:
        return [pattern]
    depth = 0
    for i in range(start, len(pattern)):
        if pattern[i] == "{":
            depth += 1
        elif pattern[i] == "}":
            depth -= 1
            if depth == 0:
                inside = pattern[start+1:i]
                before = pattern[:start]
                after = pattern[i+1:]
                parts = [p.strip() for p in inside.split(",") if p.strip()]
                expanded = [before + p + after for p in parts]
                result: List[str] = []
                for e in expanded:
                    result.extend(_brace_expand_one(e))
                return result
    return [pattern]

def _brace_expand(pattern: str) -> List[str]:
    acc = [pattern]
    changed = True
    while changed:
        changed = False
        new_acc: List[str] = []
        for p in acc:
            expanded = _brace_expand_one(p)
            if len(expanded) > 1 or expanded[0] != p:
                changed = True
            new_acc.extend(expanded)
        acc = new_acc
    return acc

def _normalize_pattern(pat: str) -> str:
    while pat.startswith("/"):
        pat = pat[1:]
    return pat

def _expand_patterns(patterns: List[str]) -> List[str]:
    out: List[str] = []
    for pat in patterns or []:
        pat = _normalize_pattern(pat)
        out.extend(_brace_expand(pat))
    seen, uniq = set(), []
    for p in out:
        if p not in seen:
            seen.add(p); uniq.append(p)
    return uniq

def _apply_filename_search(patterns: List[str], filename_search: bool) -> List[str]:
    """NÃ¥r pÃ¥: mÃ¸nstre uten '/' blir '**/<mÃ¸nster>' for global match."""
    if not filename_search:
        return patterns or []
    out: List[str] = []
    for pat in patterns or []:
        if ("/" not in pat) and (not pat.startswith("**/")):
            out.append(f"**/{pat}")
        else:
            out.append(pat)
    return out

def _collect_files(root: Path, includes: List[str], excludes: List[str],
                   only_globs: List[str] | None, skip_globs: List[str] | None) -> List[Path]:
    root = root.resolve()
    includes = _expand_patterns(includes)
    excludes = _expand_patterns(excludes)
    only_globs = _expand_patterns(only_globs or [])
    skip_globs = _expand_patterns(skip_globs or [])

    candidates: set[Path] = set()
    if only_globs:
        for pat in only_globs:
            for p in root.glob(pat):
                if p.is_file():
                    candidates.add(p.resolve())
                elif p.is_dir():
                    for sub in p.rglob("*"):
                        if sub.is_file():
                            candidates.add(sub.resolve())
    else:
        for p in root.rglob("*"):
            if p.is_file():
                candidates.add(p.resolve())

    for pat in skip_globs:
        for p in root.glob(pat):
            if p.is_file() and p.resolve() in candidates:
                candidates.remove(p.resolve())
            elif p.is_dir():
                for sub in p.rglob("*"):
                    rp = sub.resolve()
                    if sub.is_file() and rp in candidates:
                        candidates.discard(rp)

    include_set: set[Path] = set()
    for pat in includes:
        for p in root.glob(pat):
            if p.is_file():
                include_set.add(p.resolve())

    exclude_set: set[Path] = set()
    for pat in excludes:
        for p in root.glob(pat):
            if p.is_file():
                exclude_set.add(p.resolve())
            elif p.exists() and p.is_dir():
                for sub in p.rglob("*"):
                    if sub.is_file():
                        exclude_set.add(sub.resolve())

    files = sorted([p for p in candidates if p in include_set and p not in exclude_set])
    return files

def _build_framed_block(path: Path, content: str, sha256: str) -> str:
    content = _normalize_newlines(content)
    line_count = content.count("\n") + (0 if content.endswith("\n") else 1)
    header = [
        FRAME_TOP,
        f"PATH: {path.as_posix()}",
        f"LINES: {line_count}",
        "CHUNK: 1/1",
        f"SHA256: {sha256}",
        CODE_BEGIN,
    ]
    footer = [CODE_END, FRAME_END]
    return "\n".join(header) + "\n" + content + "\n" + "\n".join(footer) + "\n"

def _write_chunks(blocks: List[Tuple[Path, str]], out_dir: Path, max_lines: int) -> List[Path]:
    out_dir.mkdir(parents=True, exist_ok=True)
    outputs: List[Path] = []
    buf: List[str] = []
    buf_lines = 0
    part = 1

    def flush():
        nonlocal buf, buf_lines, part
        if not buf:
            return
        out_path = out_dir / f"paste_{part:03d}.txt"
        with out_path.open("w", encoding="utf-8") as f:
            f.write("".join(buf))
        outputs.append(out_path)
        buf = []
        buf_lines = 0

    def count_lines(s: str) -> int:
        return s.count("\n") + (0 if s.endswith("\n") else 1)

    for (_path, block) in blocks:
        block_lines = count_lines(block)
        if buf_lines + block_lines > max_lines and buf:
            flush()
            part += 1
        buf.append(block)
        buf_lines += block_lines

    flush()
    return outputs

def _create_index(mapping: List[Tuple[Path, Path]], out_dir: Path) -> Path:
    index_path = out_dir / "INDEX.txt"
    with index_path.open("w", encoding="utf-8") as f:
        f.write("# Index over filer og hvilken paste_NNN.txt de ligger i\n\n")
        current = None
        for out_file, src in mapping:
            if out_file != current:
                f.write(f"\n## {out_file.name}\n")
                current = out_file
            f.write(f"- {src.as_posix()}\n")
    return index_path

def _write_files_list(root: Path, sources: List[Path], out_dir: Path) -> Path:
    """Skriv FILES.txt med alle inkluderte filer (relative paths)."""
    files_txt = out_dir / "FILES.txt"
    rels = [s.relative_to(root).as_posix() for s in sources]
    rels.sort()
    with files_txt.open("w", encoding="utf-8") as f:
        for r in rels:
            f.write(r + "\n")
    return files_txt

def _resolve_relative(root: Path, maybe_path: str | None, default_rel: str) -> Path:
    if not maybe_path:
        return (root / default_rel).resolve()
    p = Path(maybe_path)
    if p.is_absolute():
        return p.resolve()
    return (root / p).resolve()

def run_paste(cfg: Dict, list_only: bool = False) -> None:
    pcfg: Dict = cfg.get("paste", {})
    project_root = Path(cfg.get("project_root", ".")).resolve()
    root = _resolve_relative(project_root, pcfg.get("root", "."), ".")
    out_dir = _resolve_relative(root, pcfg.get("out_dir", "paste_out"), "paste_out")

    includes = list(pcfg.get("include", []))
    excludes = list(pcfg.get("exclude", []))
    only_globs = list(pcfg.get("only_globs", []))
    skip_globs = list(pcfg.get("skip_globs", []))
    max_lines = int(pcfg.get("max_lines", 4000))
    allow_binary = bool(pcfg.get("allow_binary", False))
    filename_search = bool(pcfg.get("filename_search", False))

    # Filnavn-sÃ¸k: utvid bÃ¥de include og exclude
    includes = _apply_filename_search(includes, filename_search)
    excludes = _apply_filename_search(excludes, filename_search)

    sources = _collect_files(root, includes, excludes, only_globs, skip_globs)
    if not sources:
        print("Ingen filer funnet med de angitte mÃ¸nstrene.")
        return

    if list_only:
        print(f"{len(sources)} fil(er):")
        for s in sources:
            print("-", s.relative_to(root).as_posix())
        return

    blocks: List[Tuple[Path, str]] = []
    skipped: List[Path] = []
    for src in sources:
        if _is_text_utf8(src):
            text = _read_text_utf8(src)
            digest = _sha256_file(src)
            rel = src.relative_to(root)
            block = _build_framed_block(rel, text, digest)
            blocks.append((src, block))
        else:
            if allow_binary:
                with src.open("rb") as f:
                    data = f.read()
                digest = hashlib.sha256(data).hexdigest()
                rel = src.relative_to(root)
                block = _build_framed_block(rel, data.hex(), digest)
                blocks.append((src, block))
            else:
                skipped.append(src)

    blocks.sort(key=lambda t: t[0].as_posix())
    outputs = _write_chunks(blocks, out_dir, max_lines)

    mapping: List[Tuple[Path, Path]] = []
    for out_file in outputs:
        with out_file.open("r", encoding="utf-8") as f:
            for line in f:
                if line.startswith("PATH: "):
                    p = line.strip().split("PATH: ", 1)[1]
                    mapping.append((out_file, Path(p)))
    index_path = _create_index(mapping, out_dir)

    # Skriv og vis inkluderte filer
    files_list_path = _write_files_list(root, sources, out_dir)

    print(f"Skrev {len(outputs)} output-fil(er) til: {out_dir.as_posix()}")
    for p in outputs:
        with p.open("r", encoding="utf-8") as fh:
            lc = sum(1 for _ in fh)
        print(f" - {p.name}  ({lc} linjer)")

    if skipped:
        print("\nHoppet over binÃ¦r/ikke-UTF8-filer (sett paste.allow_binary=true for Ã¥ inkludere):")
        for s in skipped:
            print(f" - {s.relative_to(root).as_posix()}")

    print("\nInkluderte filer:")
    for src in sources:
        print(f" - {src.relative_to(root).as_posix()}")

    print(f"\nFILES: {files_list_path.as_posix()}")
    print(f"INDEX: {index_path.as_posix()}")

----- END CODE -----
===== END FILE =====
===== BEGIN FILE =====
PATH: r_tools/tools/webui.py
LINES: 475
CHUNK: 1/1
SHA256: 0a9e519ec382f7a3aa5e9c95e875ac6550e30d1d199c5a3db3c8db6874e3165a
----- BEGIN CODE -----
# /home/reidar/tools/r_tools/tools/webui.py
from __future__ import annotations
import io, json
from contextlib import redirect_stdout
from pathlib import Path
from typing import TypedDict, Any, Dict, List, Optional

from fastapi import FastAPI, HTTPException
from fastapi.responses import HTMLResponse, JSONResponse, Response
from pydantic import BaseModel

from ..config import load_config
from .code_search import run_search
from .paste_chunks import run_paste
from .format_code import run_format
from .clean_temp import run_clean
from .gh_raw import run_gh_raw

# Viktig: pek til /tools/configs (ikke r_tools/configs)
ROOT_DIR = Path(__file__).resolve().parents[2]   # .../tools
CONFIG_DIR = ROOT_DIR / "configs"

class ProjectEntry(TypedDict):
    name: str
    path: str       # som i JSON (kan vÃ¦re relativ)
    abs_path: str   # opplÃ¸st absolutt path
    exists: bool    # finnes pÃ¥ disk?

def _load_projects() -> List[ProjectEntry]:
    cfg_path = CONFIG_DIR / "projects_config.json"
    if not cfg_path.is_file():
        raise FileNotFoundError(f"Fant ikke {cfg_path}")

    data = json.loads(cfg_path.read_text(encoding="utf-8"))
    projects = data.get("projects")
    if not isinstance(projects, list):
        raise ValueError(f"{cfg_path}: 'projects' mÃ¥ vÃ¦re en liste")

    out: List[ProjectEntry] = []
    for i, p in enumerate(projects):
        if not isinstance(p, dict) or "name" not in p or "path" not in p:
            raise ValueError(f"{cfg_path}: item[{i}] mangler 'name' eller 'path'")

        raw_path = str(p["path"])
        base = ROOT_DIR  # relativ path tolkes relativt til tools/
        abs_path = (Path(raw_path).expanduser()
                    if Path(raw_path).is_absolute()
                    else (base / raw_path)).resolve()

        out.append(ProjectEntry(
            name=str(p["name"]),
            path=raw_path,
            abs_path=str(abs_path),
            exists=abs_path.exists(),
        ))

    if not out:
        raise ValueError(f"{cfg_path}: 'projects' er tom")
    return out

def _load_recipes() -> List[Dict[str, Any]]:
    rc = CONFIG_DIR / "recipes_config.json"
    if not rc.is_file():
        return []
    data = json.loads(rc.read_text(encoding="utf-8"))
    return list(data.get("recipes", []))

def _capture(fn, *args, **kwargs) -> str:
    buf = io.StringIO()
    with redirect_stdout(buf):
        fn(*args, **kwargs)
    return buf.getvalue()

app = FastAPI(title="r_tools UI", default_response_class=JSONResponse)

INDEX_HTML = """<!doctype html>
<html lang="no">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>r_tools UI</title>
<style>
  :root{--pad:14px;--gap:12px;--radius:14px;font-family:system-ui,Segoe UI,Roboto,Helvetica,Arial;}
  body{margin:0;background:#0b0c10;color:#e9ecef}
  header{padding:var(--pad);background:#11131a;border-bottom:1px solid #1b1f2a;position:sticky;top:0}
  main{padding:var(--pad);max-width:1100px;margin:0 auto}
  .row{display:grid;gap:var(--gap)}
  @media(min-width:1080px){.row{grid-template-columns:repeat(2,1fr)}}
  .card{background:#121622;border:1px solid #1b2030;border-radius:var(--radius);padding:var(--pad);box-shadow:0 6px 16px rgba(0,0,0,.25)}
  h1{font-size:20px;margin:0}
  h2{font-size:18px;margin:6px 0 12px}
  label{display:block;margin:8px 0 4px}
  input[type=text],input[type=number],textarea,select{width:100%;padding:10px;background:#0e1220;color:#e6eef9;border:1px solid #23304a;border-radius:10px}
  textarea{min-height:160px;font-family:ui-monospace,Menlo,Consolas,monospace}
  .btn{display:inline-block;padding:10px 14px;border-radius:10px;border:1px solid #2b3550;background:#1a2340;color:#dce6ff;cursor:pointer}
  .btn:hover{background:#223055}
  .inline{display:flex;gap:10px;align-items:center;flex-wrap:wrap}
  .muted{color:#9fb0c9;font-size:12px}
  .pill{display:inline-block;padding:4px 8px;border-radius:9999px;background:#19223c;border:1px solid #263356;margin:2px}
</style>
</head>
<body>
<header class="inline">
  <h1 style="flex:1">r_tools UI</h1>
  <div>
    <label for="project">Prosjekt</label>
    <select id="project" title="Defineres i tools/configs/projects_config.json"></select>
  </div>
  <button class="btn" id="refresh">Oppdater</button>
</header>
<main>
  <section class="card" id="recipes_card">
    <h2>Oppskrifter</h2>
    <div id="recipes"></div>
    <p class="muted">Oppskrifter kommer fra <code>tools/configs/recipes_config.json</code>.</p>
  </section>

  <div class="row">
    <section class="card">
      <h2>Search</h2>
      <label>Termer (regex, separert med komma)</label>
      <input id="search_terms" type="text" placeholder="f.eks: import\\s+os, class"/>
      <div class="inline">
        <label><input type="checkbox" id="search_all"/> Krev alle termer (--all)</label>
        <label><input type="checkbox" id="search_case"/> Skill store/smÃ¥ (--case-sensitive)</label>
        <label>Max size <input id="search_max" type="number" value="2000000"/></label>
      </div>
      <div class="inline"><button class="btn" id="run_search">KjÃ¸r search</button></div>
      <label>Resultat</label><textarea id="out_search" readonly></textarea>
      <p class="muted">Tomt felt â†’ bruker ev. <code>search_terms</code> fra config.</p>
    </section>

    <section class="card">
      <h2>Paste</h2>
      <div class="inline">
        <label><input type="checkbox" id="paste_list_only"/> Kun liste</label>
        <label><input type="checkbox" id="paste_filename_search" checked/> Filnavn-sÃ¸k globalt</label>
        <label>Max linjer<input id="paste_max" type="number" value="4000"/></label>
      </div>
      <label>Out dir (relativ til prosjekt)</label>
      <input id="paste_out" type="text" placeholder="paste_out"/>
      <label>Include (linje per mÃ¸nster)</label>
      <textarea id="paste_include" placeholder="**/*.py&#10;README.md"></textarea>
      <label>Exclude (linje per mÃ¸nster)</label>
      <textarea id="paste_exclude" placeholder="**/.git/**&#10;**/venv/**"></textarea>
      <div class="inline"><button class="btn" id="run_paste">KjÃ¸r paste</button></div>
      <label>Resultat</label><textarea id="out_paste" readonly></textarea>
    </section>

    <section class="card">
      <h2>Format</h2>
      <div class="inline"><label><input type="checkbox" id="format_dry" /> Dry-run</label></div>
      <div class="inline"><button class="btn" id="run_format">KjÃ¸r format</button></div>
      <label>Resultat</label><textarea id="out_format" readonly></textarea>
      <p class="muted">Bruker prettier/black/ruff + cleanup fra config.</p>
    </section>

    <section class="card">
      <h2>Clean</h2>
      <div class="inline">
        <label><input type="checkbox" id="clean_yes" /> UtfÃ¸r sletting</label>
        <label><input type="checkbox" id="clean_dry" /> Dry-run</label>
      </div>
      <label>Begrens til mÃ¥l (komma-separert)</label>
      <input id="clean_what" type="text" placeholder="pycache,ruff_cache"/>
      <label>Skip mÃ¥l (komma-separert)</label>
      <input id="clean_skip" type="text" placeholder="node_modules"/>
      <div class="inline"><button class="btn" id="run_clean">KjÃ¸r clean</button></div>
      <label>Resultat</label><textarea id="out_clean" readonly></textarea>
    </section>

    <section class="card">
      <h2>GH Raw</h2>
      <label>Path prefix</label>
      <input id="gh_prefix" type="text" placeholder="app/routes"/>
      <div class="inline"><button class="btn" id="run_gh">List raw-URLer</button></div>
      <label>Resultat</label><textarea id="out_gh" readonly></textarea>
    </section>
  </div>
</main>

<script>
const PREF_KEY = (proj) => `rtools:prefs:${proj}`;

async function fetchProjects() {
  const r = await fetch('/api/projects');
  const data = await r.json();
  const sel = document.getElementById('project');
  sel.innerHTML = '';

  if (data.error) {
    const opt = document.createElement('option');
    opt.value = '';
    opt.textContent = 'Ingen prosjekter (se konsollen)';
    sel.appendChild(opt);
    console.warn('Prosjektfeil:', data.error, 'Config:', data.config);
    alert(`Kunne ikke laste prosjekter.\\n\\n${data.error}\\n\\nForventet fil:\\n${data.config}`);
    return;
  }

  const projs = data.projects || [];
  let firstValid = '';
  projs.forEach(p => {
    const opt = document.createElement('option');
    const badge = p.exists ? "âœ“" : "âš ";
    opt.value = p.abs_path;                // bruk absolutt sti ved kjÃ¸ring
    opt.textContent = `${badge} ${p.name} â€” ${p.path}`;
    opt.title = p.exists ? p.abs_path : `Sti finnes ikke: ${p.abs_path}`;
    sel.appendChild(opt);
    if (p.exists && !firstValid) firstValid = p.abs_path;
  });

  sel.value = firstValid || (projs[0]?.abs_path || '');

  if (projs.length && projs.every(p => !p.exists)) {
    alert("Ingen av prosjektene i projects_config.json finnes pÃ¥ disk.\\n\\nSjekk stiene.");
  }
}

async function fetchRecipes() {
  const r = await fetch('/api/recipes');
  const data = await r.json();
  const root = document.getElementById('recipes');
  root.innerHTML = '';
  (data.recipes || []).forEach((rec, idx) => {
    const row = document.createElement('div');
    row.className = 'inline';
    const btn = document.createElement('button');
    btn.className = 'btn';
    btn.textContent = rec.name || `Oppskrift ${idx+1}`;
    btn.onclick = async () => {
      await runTool(rec.tool, {args: rec.args || {}}, guessOutputTarget(rec.tool));
    };
    const info = document.createElement('span');
    info.className = 'muted';
    info.textContent = rec.desc || '';
    row.appendChild(btn);
    row.appendChild(info);
    root.appendChild(row);
  });
  if ((data.recipes || []).length === 0) {
    const p = document.createElement('p');
    p.className='muted';
    p.textContent='Ingen oppskrifter funnet.';
    root.appendChild(p);
  }
}

function guessOutputTarget(tool){
  return tool === 'search' ? 'out_search'
       : tool === 'paste'  ? 'out_paste'
       : tool === 'format' ? 'out_format'
       : tool === 'clean'  ? 'out_clean'
       : 'out_gh';
}

function currentProject(){ return document.getElementById('project').value; }

function savePrefs(){
  const proj = currentProject();
  if(!proj) return;
  const prefs = {
    search_terms: document.getElementById('search_terms').value,
    search_all: document.getElementById('search_all').checked,
    search_case: document.getElementById('search_case').checked,
    search_max: document.getElementById('search_max').value,
    paste_list_only: document.getElementById('paste_list_only').checked,
    paste_filename_search: document.getElementById('paste_filename_search').checked,
    paste_max: document.getElementById('paste_max').value,
    paste_out: document.getElementById('paste_out').value,
    paste_include: document.getElementById('paste_include').value,
    paste_exclude: document.getElementById('paste_exclude').value,
    format_dry: document.getElementById('format_dry').checked,
    clean_yes: document.getElementById('clean_yes').checked,
    clean_dry: document.getElementById('clean_dry').checked,
    clean_what: document.getElementById('clean_what').value,
    clean_skip: document.getElementById('clean_skip').value,
    gh_prefix: document.getElementById('gh_prefix').value
  };
  localStorage.setItem(PREF_KEY(proj), JSON.stringify(prefs));
}

function loadPrefs(){
  const proj = currentProject();
  if(!proj) return;
  const raw = localStorage.getItem(PREF_KEY(proj));
  if(!raw) return;
  try{
    const p = JSON.parse(raw);
    const set = (id,val,chk=false)=>{ const el=document.getElementById(id); if(!el) return; if(chk) el.checked=!!val; else el.value = val ?? el.value; };
    set('search_terms', p.search_terms);
    set('search_all', p.search_all, true);
    set('search_case', p.search_case, true);
    set('search_max', p.search_max);
    set('paste_list_only', p.paste_list_only, true);
    set('paste_filename_search', p.paste_filename_search, true);
    set('paste_max', p.paste_max);
    set('paste_out', p.paste_out);
    set('paste_include', p.paste_include);
    set('paste_exclude', p.paste_exclude);
    set('format_dry', p.format_dry, true);
    set('clean_yes', p.clean_yes, true);
    set('clean_dry', p.clean_dry, true);
    set('clean_what', p.clean_what);
    set('clean_skip', p.clean_skip);
    set('gh_prefix', p.gh_prefix);
  }catch{}
  document.getElementById('refresh').onclick = async () => {
  await fetchProjects();
  await fetchRecipes();
  loadPrefs(); // re-appliker preferanser for valgt prosjekt
};

}

['project','search_terms','search_all','search_case','search_max',
 'paste_list_only','paste_filename_search','paste_max','paste_out','paste_include','paste_exclude',
 'format_dry','clean_yes','clean_dry','clean_what','clean_skip','gh_prefix'
].forEach(id=>{
  document.addEventListener('change', (e)=>{ if(e.target && e.target.id===id) savePrefs(); });
  document.addEventListener('input', (e)=>{ if(e.target && e.target.id===id) savePrefs(); });
});

document.getElementById('project').addEventListener('change', loadPrefs);
document.getElementById('refresh').onclick = ()=>{ fetchProjects(); fetchRecipes(); };

async function runTool(tool, payload, outId) {
  payload = payload || {};
  const projectPath = currentProject();
  payload.project = projectPath;
  payload.tool = tool;
  const r = await fetch('/api/run', {method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify(payload)});
  const data = await r.json();
  document.getElementById(outId).value = data.output || data.error || '';
}

document.getElementById('run_search').onclick = () => {
  const terms = document.getElementById('search_terms').value.trim();
  runTool('search',{
    args:{
      terms: terms ? terms.split(',').map(s=>s.trim()).filter(Boolean) : [],
      case_sensitive: document.getElementById('search_case').checked,
      all: document.getElementById('search_all').checked,
      max_size: parseInt(document.getElementById('search_max').value || '2000000',10)
    }
  }, 'out_search');
};

document.getElementById('run_paste').onclick = () => {
  const inc = document.getElementById('paste_include').value.split('\\n').map(s=>s.trim()).filter(Boolean);
  const exc = document.getElementById('paste_exclude').value.split('\\n').map(s=>s.trim()).filter(Boolean);
  runTool('paste',{
    args:{
      list_only: document.getElementById('paste_list_only').checked,
      out_dir: document.getElementById('paste_out').value.trim(),
      max_lines: parseInt(document.getElementById('paste_max').value || '4000',10),
      filename_search: document.getElementById('paste_filename_search').checked,
      include: inc,
      exclude: exc
    }
  }, 'out_paste');
};

document.getElementById('run_format').onclick = () => {
  runTool('format', { args:{ dry_run: document.getElementById('format_dry').checked } }, 'out_format');
};

document.getElementById('run_clean').onclick = () => {
  const what = document.getElementById('clean_what').value.trim();
  const skip = document.getElementById('clean_skip').value.trim();
  runTool('clean', { args:{
    yes: document.getElementById('clean_yes').checked,
    dry_run: document.getElementById('clean_dry').checked,
    what: what ? what.split(',').map(s=>s.trim()).filter(Boolean) : [],
    skip: skip ? skip.split(',').map(s=>s.trim()).filter(Boolean) : []
  } }, 'out_clean');
};

document.getElementById('run_gh').onclick = () => {
  runTool('gh-raw', { args:{ path_prefix: document.getElementById('gh_prefix').value.trim() } }, 'out_gh');
};

fetchProjects(); fetchRecipes(); loadPrefs();
</script>
</body></html>
"""

class RunPayload(BaseModel):
    tool: str
    project: Optional[str] = None
    args: Dict[str, Any] = {}

@app.get("/", response_class=HTMLResponse)
def index():
    return HTMLResponse(INDEX_HTML)

@app.get("/api/projects")
def api_projects():
    cfgp = str((CONFIG_DIR / "projects_config.json").resolve())
    try:
        projs = _load_projects()
        return {"projects": projs, "config": cfgp}
    except Exception as e:
        return {"projects": [], "error": f"{type(e).__name__}: {e}", "config": cfgp}

@app.get("/api/recipes")
def api_recipes():
    try:
        return {"recipes": _load_recipes()}
    except Exception:
        return {"recipes": []}

@app.post("/api/run")
def api_run(body: RunPayload):
    tool = body.tool
    project_path = Path(body.project).resolve() if body.project else None
    args = body.args or {}
    tool_cfg = {
        "search": "search_config.json",
        "paste": "paste_config.json",
        "gh-raw": "gh_raw_config.json",
        "format": "format_config.json",
        "clean": "clean_config.json",
    }.get(tool, None)

    ov: Dict[str, Any] = {}
    if project_path:
        ov["project_root"] = str(project_path)

    try:
        if tool == "search":
            cfg = load_config(tool_cfg, project_path, ov or None)
            out = _capture(run_search, cfg=cfg, terms=args.get("terms") or None,
                           use_color=False, show_count=True,
                           max_size=int(args.get("max_size", 2_000_000)),
                           require_all=bool(args.get("all", False)))
            return {"output": out}
        if tool == "paste":
            pov: Dict[str, Any] = {"paste": {}}
            for key in ["out_dir", "max_lines", "include", "exclude", "filename_search"]:
                if key in args and args[key] not in (None, ""):
                    pov["paste"][key] = args[key]
            cfg = load_config(tool_cfg, project_path, pov)
            out = _capture(run_paste, cfg=cfg, list_only=bool(args.get("list_only", False)))
            return {"output": out}
        if tool == "format":
            cfg = load_config(tool_cfg, project_path, ov or None)
            out = _capture(run_format, cfg=cfg, dry_run=bool(args.get("dry_run", False)))
            return {"output": out}
        if tool == "clean":
            cfg = load_config("clean_config.json", project_path, ov or None)
            out = _capture(run_clean, cfg=cfg, only=args.get("what") or None,
                           skip=args.get("skip") or [],
                           dry_run=bool(args.get("dry_run", True)) if not bool(args.get("yes", False)) else False)
            return {"output": out}
        if tool == "gh-raw":
            gov = {"gh_raw": {}}
            if "path_prefix" in args:
                gov["gh_raw"]["path_prefix"] = args["path_prefix"]
            cfg = load_config(tool_cfg, project_path, gov)
            out = _capture(run_gh_raw, cfg=cfg, as_json=False)
            return {"output": out}
        raise HTTPException(status_code=400, detail=f"Ukjent tool: {tool}")
    except Exception as e:
        return {"error": f"{type(e).__name__}: {e}"}

# Favicon â€“ unngÃ¥ 404-stÃ¸y
@app.get("/favicon.ico")
def favicon():
    png_1x1 = (
        b"\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01"
        b"\x08\x06\x00\x00\x00\x1f\x15\xc4\x89\x00\x00\x00\x0bIDATx\x9cc``\x00"
        b"\x00\x00\x02\x00\x01\xe2!\xbc3\x00\x00\x00\x00IEND\xaeB`\x82"
    )
    return Response(content=png_1x1, media_type="image/png")

----- END CODE -----
===== END FILE =====
